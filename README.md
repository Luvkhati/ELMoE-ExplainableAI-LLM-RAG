**llm-ml-rag-evaluation** is a framework that compares how Large Language Models (LLMs) predict, explain, and generate counterfactuals against traditional Machine Learning models. It uses clustering-based Retrieval Augmented Generation (RAG) to provide relevant data context to LLMs and evaluates their outputs against ML model predictions and baseline methods like LIME and DiCE, helping assess the reliability and usefulness of LLM-based explanations.
